**VR Therapy with Emotion Detection using Deep Learning**
Project Overview
This project integrates Virtual Reality (VR) therapy with deep learning-based emotion detection. The VR environment is designed to help users overcome their fears related to heights, darkness, and bugs through exposure therapy within a wildlife adventure scenario.

To enhance the therapeutic experience, the project uses physiological sensor data such as pulse rate and skin conductance to predict emotional states like fear, stress, and amusement. The emotional state detected influences the behavior of creatures in the VR environment, creating a dynamic and immersive therapeutic session.

We utilize the WESAD (Wearable Stress and Affect Detection) dataset(https://uni-siegen.sciebo.de/s/HGdUkoNlW1Ub0Gx) for emotion classification based on sensor data such as BVP (Blood Volume Pulse), EDA (Electrodermal Activity), temperature, and accelerometer data. The emotion prediction model is built using LSTM neural networks.
